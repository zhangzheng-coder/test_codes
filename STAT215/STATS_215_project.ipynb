{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "pd.set_option('display.max_rows', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and count check.\n",
    "This portion of the code is intended to load the datafiles into dataframes to better handling and join. Also, will present the verification of the results from Table 2 presented in the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520). \n",
    "\n",
    "In the following lines of code we have dropped the columns not relevant for the analysis, the final outcome are dataframes for each data sample and a merged dataframe with all the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Colony dataframes\n",
    "bishayee_colony = pd.read_excel(\"Bishayee Colony Counts 10.27.97-3.8.01.xlsx\", skiprows=2,na_values=\" \")\n",
    "outside3_colony = pd.read_excel(\"Outside Lab 3.Colony Counts.2.4.10-5.21.12.xlsx\", skiprows=1)\n",
    "others_colony = pd.read_excel(\"Other Investigators in Lab.Colony Counts.4.23.92-11.27.02.xlsx\", skiprows=1)\n",
    "    #Clean up of the colony data\n",
    "bishayee_colony[\"Inv\"] = \"Z\"\n",
    "bishayee_colony.drop('ISOTOPE', axis=1, inplace=True)\n",
    "bishayee_colony2 = bishayee_colony.iloc[:,[0,1,6,2,3,4,5]]\n",
    "bishayee_colony2.columns\n",
    "bishayee_colony2.rename(columns={'Bate # B0/B00':'Batch'},inplace = True)\n",
    "bishayee_colony2.drop('Batch', axis=1, inplace=True)\n",
    "bishayee_colony2.drop(\"Date\",axis =1,inplace=True)\n",
    "others_colony2 = others_colony.rename(columns={'Bates # B00 or B0':'Batch'})\n",
    "others_colony2.drop('Batch', axis=1, inplace=True)\n",
    "others_colony2.drop(\"Date\",axis =1,inplace=True)\n",
    "outside3_colony[\"Inv\"] = \"O\"\n",
    "outside3_colony2=outside3_colony.iloc[:,[0,5,1,2,3,4]]\n",
    "outside3_colony2.rename(columns={'date':'Date','c1':'col1','c2':'col2','c3':'col3'},inplace = True)\n",
    "outside3_colony2.drop(\"Date\",axis =1,inplace=True)\n",
    "df_total = [bishayee_colony2,others_colony2,outside3_colony2]\n",
    "merged_colony_data = pd.concat(df_total)    \n",
    "#Coulter dataframes\n",
    "bishayee_coulter = pd.read_excel(\"Bishayee Coulter Counts.10.20.97-7.16.01.xlsx\", skiprows=1)\n",
    "others_coulter = pd.read_excel(\"Other Investigators in Lab.Coulter Counts.4.15.92-5.21.05.xlsx\", skiprows=1)\n",
    "    #This data file had no header, introduced manually\n",
    "outside1_coulter = pd.read_excel(\"Outside Lab 1.Coulter Counts.6.7.91-4.9.99.xlsx\")\n",
    "outside1_coulter.columns = [\"Experiment\", \"C1\", \"C2\", \"C3\",\"Average\",\"Date\"]\n",
    "outside2_coulter = pd.read_excel(\"Outside Lab 2.Coulter Counts.6.6.08-7.7.08.xlsx\", skiprows=1)\n",
    "    #Clean up of the coulter data \n",
    "bishayee_coulter2 = bishayee_coulter.drop('Bates', axis=1)\n",
    "bishayee_coulter2[\"Inv\"] = \"Z\"\n",
    "bishayee_coulter2 = bishayee_coulter2.iloc[:,[0,5,1,2,3,4]]\n",
    "bishayee_coulter2.rename(columns={'Count 1':'col1','Count 2':'col2','Count 3':'col3'},inplace=True)\n",
    "bishayee_coulter2.drop(\"Date\",axis =1,inplace=True)\n",
    "outside1_coulter2 = outside1_coulter.drop('Experiment', axis = 1)\n",
    "outside1_coulter2[\"Inv\"] = \"O1\"\n",
    "outside1_coulter2 = outside1_coulter2.iloc[:,[4,5,0,1,2,3]]\n",
    "outside1_coulter2.rename(columns={'C1':'col1','C2':'col2','C3':'col3'},inplace=True)\n",
    "outside1_coulter2.drop(\"Date\",axis =1,inplace=True)\n",
    "outside2_coulter2 = outside2_coulter.rename(columns={'Count 1':\"col1\",'Count 2':\"col2\",'Count 3':\"col3\"})\n",
    "outside2_coulter2[\"Inv\"] = \"O2\"\n",
    "outside2_coulter2 = outside2_coulter2.iloc[:,[0,5,1,2,3,4]]\n",
    "outside2_coulter2.drop(\"Date\",axis =1,inplace=True)\n",
    "others_coulter2 = others_coulter.drop('Bates No.', axis = 1)\n",
    "others_coulter2.rename(columns={'Coul 1':'col1','Coul 2':'col2','Coul 3':'col3','Investigator':'Inv'},\\\n",
    "                       inplace=True)\n",
    "others_coulter2 = others_coulter2.iloc[:,[0,5,1,2,3,4]]\n",
    "others_coulter2.drop(\"Date\",axis =1,inplace=True)\n",
    "df_total_coulter = [bishayee_coulter2,others_coulter2,outside1_coulter2,outside2_coulter2]\n",
    "merged_coulter_data = pd.concat(df_total_coulter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step is to verify the magnitudes of the data in the sets for the coulter and the colony. From the description of the experimental set-up, it seems that the count of the cells using the coulter and the colony count are actually individual experiments with different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completeness test of the combined colony data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of colony data triplets  2033\n",
      "Total number of suspected colony data triplets  1362\n",
      "Total number of others colony data triplets  621\n",
      "Total number of outside lab 3 colony data triplets  50\n"
     ]
    }
   ],
   "source": [
    "print 'Total number of colony data triplets  ' + str(merged_colony_data.index.size)\n",
    "print 'Total number of suspected colony data triplets  ' + str(bishayee_colony2.index.size)\n",
    "print 'Total number of others colony data triplets  ' + str(others_colony2.index.size)\n",
    "print 'Total number of outside lab 3 colony data triplets  ' + str(outside3_colony2.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw total number of samples doesn't coincide with the numbers in the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520). Furthermore, the labeling of the outside labs is not consistent. It looks like the authors labeled the outside colony counts at lab1 when indeed is lab3. \n",
    "\n",
    "The following step is to eliminate incomplete triples and drop the na rows and check again against the authors' table. The designation (AD) is used to differentiate the data after drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of colony data triplets (AD) 2008\n",
      "Total number of suspected colony data triplets (AD) 1361\n",
      "Total number of others colony data triplets (AD) 597\n",
      "Total number of outside lab 3 colony data triplets  50\n"
     ]
    }
   ],
   "source": [
    "merged_colony_data.replace(r'\\s*',np.nan, regex=True)\n",
    "merged_colony_data=merged_colony_data.dropna()\n",
    "merged_colony_data.reset_index(drop=True)\n",
    "print 'Total number of colony data triplets (AD) ' + str(merged_colony_data.index.size) \n",
    "bishayee_colony2.replace(r'\\s*',np.nan, regex=True)\n",
    "bishayee_colony2 = bishayee_colony2.dropna()\n",
    "bishayee_colony2.reset_index(drop=True)\n",
    "print 'Total number of suspected colony data triplets (AD) ' + str(bishayee_colony2.index.size)\n",
    "others_colony2.replace(r'\\s*',np.nan, regex=True)\n",
    "others_colony2 = others_colony2.dropna()\n",
    "others_colony2.reset_index(drop=True)\n",
    "print 'Total number of others colony data triplets (AD) ' + str(others_colony2.index.size)\n",
    "outside3_colony2.replace(r'\\s*',np.nan, regex=True)\n",
    "outside3_colony2 = outside3_colony2.dropna()\n",
    "outside3_colony2.reset_index(drop=True)\n",
    "print 'Total number of outside lab 3 colony data triplets  ' + str(outside3_colony2.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data clean up and count of the the triplets is performed with the coulter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of coulter data triplets  2965\n",
      "Total number of suspected coulter data triplets  1729\n",
      "Total number of others coulter data triplets  1007\n",
      "Total number of outside lab1 data triplets  109\n",
      "Total number of outside lab2 data triplets  120\n"
     ]
    }
   ],
   "source": [
    "print 'Total number of coulter data triplets  ' + str(merged_coulter_data.index.size)\n",
    "print 'Total number of suspected coulter data triplets  ' + str(bishayee_coulter2.index.size)\n",
    "print 'Total number of others coulter data triplets  ' + str(others_coulter2.index.size)\n",
    "print 'Total number of outside lab1 data triplets  ' + str(outside1_coulter2.index.size)\n",
    "print 'Total number of outside lab2 data triplets  ' + str(outside2_coulter2.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of coulter data triplets (AD) 2873\n",
      "Total number of suspected coulter data triplets (AD) 1727\n",
      "Total number of others coulter data triplets (AD) 929\n",
      "Total number of outside lab1 data triplets (AD) 97\n",
      "Total number of outside lab2 data triplets (AD) 120\n"
     ]
    }
   ],
   "source": [
    "merged_coulter_data.replace(r'\\s*',np.nan, regex=True)\n",
    "merged_coulter_data = merged_coulter_data.dropna()\n",
    "merged_coulter_data.reset_index(drop=True)\n",
    "print 'Total number of coulter data triplets (AD) ' + str(merged_coulter_data.index.size)\n",
    "bishayee_coulter2.replace(r'\\s*',np.nan, regex=True)\n",
    "bishayee_coulter2 = bishayee_coulter2.dropna()\n",
    "bishayee_coulter2.reset_index(drop=True)\n",
    "print 'Total number of suspected coulter data triplets (AD) ' + str(bishayee_coulter2.index.size)\n",
    "others_coulter2.replace(r'\\s*',np.nan, regex=True)\n",
    "others_coulter2 = others_coulter2.dropna()\n",
    "others_coulter2.reset_index(drop=True)\n",
    "print 'Total number of others coulter data triplets (AD) ' + str(others_coulter2.index.size)\n",
    "outside1_coulter2.replace(r'\\s*',np.nan, regex=True)\n",
    "outside1_coulter2 = outside1_coulter2.dropna()\n",
    "outside1_coulter2.reset_index(drop=True)\n",
    "print 'Total number of outside lab1 data triplets (AD) ' + str(outside1_coulter2.index.size)\n",
    "outside2_coulter2.replace(r'\\s*',np.nan, regex=True)\n",
    "outside2_coulter2 = outside2_coulter2.dropna()\n",
    "outside2_coulter2.reset_index(drop=True)\n",
    "print 'Total number of outside lab2 data triplets (AD) ' + str(outside2_coulter2.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the complete triples yields a discrepancy when compared to Table 2. The results of the count are consistent for \"total\" in the fourth column. The RTS (suspected) colony counts, and the outside lab3 (labeled in the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520) as lab1) are equal. The only discrepancy is the count for the other's colony count; however, the discrepancy is very small i.e., 8 triplets. \n",
    "\n",
    "In the case of the coulter counts there is no discrepancy with respect to the No. complete, the others, lab2 and lab1 (labeled in the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520) as lab3) are consistent with Table 2. The discrepancy appears in the RTS (suspected) sample, but again it is a comparatively small differnece i.e., 11. \n",
    "\n",
    "It is worth nothing that the authors dropped triplets with gap $\\ge$ 2, this is not completely explained in the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520) and it is only mentioned in a footnote in Table 2. If there are issues with the gaps, they are expected to show up in the ratio of the distances between the samples in the forthcoming analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of the distance ratios\n",
    "\n",
    "A function is used to take a dataframe and add columns with the values of the distance ratios between the samples, even though the [paper](https://www.scienceopen.com/document/review?3&id=7a235c56-a1da-498f-98ef-6fa16c8fd2f0&review=9870bf08-c06e-403a-85ba-774e27cdb520) only mentions a single ratio we tested the distances from the mid value in both directions. The proceedure for the calculations is as follows: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{sort} (\\hat{t})\\\\\n",
    "\\\\\n",
    "LowerRatio = \\frac{\\hat{t}(2) - \\hat{t}(1)}{\\hat{t}(3) - \\hat{t}(1)}\\\\\n",
    "\\\\\n",
    "UpperRatio = \\frac{\\hat{t}(3) - \\hat{t}(2)}{\\hat{t}(3) - \\hat{t}(1)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DistanceRatioCalculation(data_frame):\n",
    "    '''\n",
    "    Calculates the ratio of the distance between a triplet sample.\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\text{sort} (\\hat{t})\\\\\n",
    "    \\\\\n",
    "    LowerRatio = \\frac{\\hat{t}(2) - \\hat{t}(1)}{\\hat{t}(3) - \\hat{t}(1)}\\\\\n",
    "    \\\\\n",
    "    UpperRatio = \\frac{\\hat{t}(3) - \\hat{t}(2)}{\\hat{t}(3) - \\hat{t}(1)}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    '''\n",
    "    if not isinstance(data_frame, pd.DataFrame):\n",
    "        print 'Wrong data type, dataframe expected'\n",
    "    else:\n",
    "        data_frame[\"LowerRatio\"] = 0\n",
    "        data_frame[\"UpperRatio\"] = 0\n",
    "        for i in range(0,len(data_frame)):\n",
    "            temp_array = np.ones(3)\n",
    "            for k in range(0,3):\n",
    "                temp_array[k] = data_frame.iloc[i,(1+k)]\n",
    "            temp_array = np.sort(temp_array)\n",
    "            temp_l = (temp_array[1]-temp_array[0])/(temp_array[2]-temp_array[0])\n",
    "            temp_u = (temp_array[2]-temp_array[1])/(temp_array[2]-temp_array[0])\n",
    "            data_frame.iloc[i,5] = temp_l\n",
    "            data_frame.iloc[i,6] = temp_u\n",
    "            if (data_frame.iloc[i,5]) == 0 and (data_frame.iloc[i,6]) != 1:\n",
    "                print \"data issues\"\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of colony data triplets (AD) 1359\n",
      "Total number of suspected colony data triplets (AD) 1360\n",
      "Total number of others colony data triplets (AD) 595\n",
      "Total number of outside lab 3 colony data triplets  50\n"
     ]
    }
   ],
   "source": [
    "merged_colony_data = DistanceRatioCalculation(merged_colony_data)\n",
    "merged_colony_data = merged_colony_data.dropna()\n",
    "print 'Total number of colony data triplets (AD) ' + str(merged_colony_data.index.size) \n",
    "bishayee_colony2 = DistanceRatioCalculation(bishayee_colony2)\n",
    "bishayee_colony2 = bishayee_colony2.dropna()\n",
    "print 'Total number of suspected colony data triplets (AD) ' + str(bishayee_colony2.index.size)\n",
    "others_colony2 = DistanceRatioCalculation(others_colony2)\n",
    "others_colony2 = others_colony2.dropna()\n",
    "print 'Total number of others colony data triplets (AD) ' + str(others_colony2.index.size)\n",
    "outside3_colony2 = DistanceRatioCalculation(outside3_colony2)\n",
    "outside3_colony2 = outside3_colony2.dropna()\n",
    "print 'Total number of outside lab 3 colony data triplets  ' + str(outside3_colony2.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of coulter data triplets (AD) 2873\n",
      "Total number of suspected coulter data triplets (AD) 1727\n",
      "Total number of others coulter data triplets (AD) 929\n",
      "Total number of outside lab1 data triplets (AD) 97\n",
      "Total number of outside lab2 data triplets (AD) 120\n"
     ]
    }
   ],
   "source": [
    "merged_coulter_data = DistanceRatioCalculation(merged_coulter_data)\n",
    "merged_coulter_data = merged_coulter_data.dropna()\n",
    "print 'Total number of coulter data triplets (AD) ' + str(merged_coulter_data.index.size)\n",
    "bishayee_coulter2 = DistanceRatioCalculation(bishayee_coulter2)\n",
    "bishayee_coulter2 = bishayee_coulter2.dropna()\n",
    "print 'Total number of suspected coulter data triplets (AD) ' + str(bishayee_coulter2.index.size)\n",
    "others_coulter2 = DistanceRatioCalculation(others_coulter2)\n",
    "others_coulter2 = others_coulter2.dropna()\n",
    "print 'Total number of others coulter data triplets (AD) ' + str(others_coulter2.index.size)\n",
    "outside1_coulter2 = DistanceRatioCalculation(outside1_coulter2)\n",
    "outside1_coulter2 = outside1_coulter2.dropna()\n",
    "print 'Total number of outside lab1 data triplets (AD) ' + str(outside1_coulter2.index.size)\n",
    "outside2_coulter2 = DistanceRatioCalculation(outside2_coulter2)\n",
    "outside2_coulter2 = outside2_coulter2.dropna()\n",
    "print 'Total number of outside lab2 data triplets (AD) ' + str(outside2_coulter2.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colony_ur = merged_colony_data.as_matrix(['UpperRatio'])\n",
    "colony_ur=np.squeeze(colony_ur)\n",
    "colony_ur = colony_ur[~np.isnan(colony_ur)]\n",
    "colony_lr = merged_colony_data.as_matrix(['LowerRatio'])\n",
    "colony_lr=np.squeeze(colony_ur)\n",
    "colony_lr = colony_lr[~np.isnan(colony_lr)]\n",
    "coulter_ur = merged_coulter_data.as_matrix(['UpperRatio'])\n",
    "coulter_ur=np.squeeze(coulter_ur)\n",
    "coulter_lr = merged_coulter_data.as_matrix(['LowerRatio'])\n",
    "coulter_lr=np.squeeze(coulter_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print empirical CDF plot from a data vector x. \n",
    "def cdf_plot(x):\n",
    "    x_data = np.sort(x)\n",
    "    y_data = 1. * np.arange(len(x_data))/(len(x_data)-1)\n",
    "    plt.plot(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print coulter_ur.shape \n",
    "sample_uniform = np.random.uniform(0,1,1000)\n",
    "cdf_plot(coulter_ur)\n",
    "cdf_plot(coulter_lr)\n",
    "cdf_plot(sample_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print colony_ur.shape\n",
    "sample_uniform = np.random.uniform(0,1,1000)\n",
    "cdf_plot(colony_ur)\n",
    "cdf_plot(colony_lr)\n",
    "cdf_plot(sample_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReturnSample(l,n):\n",
    "    indexes=rnd.sample(range(1,len(l)),n)  \n",
    "    return np.asarray([l[i] for i in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniformkspermutation(data,permutations,sample_size=100):\n",
    "    \"\"\"\n",
    "    This function is designed to take a set of data and perform a KS statistic permutation test \n",
    "    against an uniform distribution sample of size 10000. The output is an array of sixe trials of KS statistics. \n",
    "    \n",
    "    inputs: data is the total population of data\n",
    "    permutations: is the number of permutations \n",
    "    sample_size: is the sample size of the data draw for each permutation\n",
    "    \"\"\"    \n",
    "    result_array = np.ones(permutations,)\n",
    "    for t in range(0,permutations):\n",
    "        permutationsample = ReturnSample(data,sample_size)\n",
    "        test_result =stats.kstest(permutationsample, 'uniform', N=1000)\n",
    "        result_array[t] = test_result[0]\n",
    "    return np.squeeze(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = uniformkspermutation(coulter_ur,1000, 200)\n",
    "plt.hist(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the ks-test for two samples in scipy is implemented as follows: \n",
    "\n",
    "```\n",
    "data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    data_all = np.concatenate([data1, data2])\n",
    "    cdf1 = np.searchsorted(data1, data_all, side='right') / (1.0*n1)\n",
    "    cdf2 = np.searchsorted(data2, data_all, side='right') / (1.0*n2)\n",
    "    d = np.max(np.absolute(cdf1 - cdf2))\n",
    "    # Note: d absolute not signed distance\n",
    "    en = np.sqrt(n1 * n2 / float(n1 + n2))\n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    except:\n",
    "        prob = 1.0\n",
    "\n",
    "    return Ks_2sampResult(d, prob)\n",
    "```\n",
    "\n",
    "If you see, it assummes that the two samples make up the whole distribution space. Hence we need to be careful on how we provide the data to not over-specify the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_test1 = ReturnSample(colony_ur,100)\n",
    "sample_test2 = ReturnSample(colony_ur,1000)\n",
    "result = stats.ks_2samp(sample_test1, sample_test2)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ks2samplepermutation(data_benchmark, data_test, trials, sample_size=100):\n",
    "    \"\"\"\n",
    "    This function is designed to take a set of the data \"data_benchmark\" and perform a KS statistic permutation test \n",
    "    against a larger sample to determine wether \"data_benchmark\" could have been produced from data with the same\n",
    "    statistical nature as the \"data_test\"\n",
    "    \"\"\"\n",
    "    if (len(data_benchmark)-len(data_test))/len(data_benchmark) < 0.5:\n",
    "        print 'The benchmarking data represents more than half of the total sample size, the test might be meaningless'\n",
    "    result_array = np.ones(trials)\n",
    "    for t in range(0,trials):\n",
    "        result = stats.ks_2samp(data_benchmark, data_test)\n",
    "        result_array[t] = result[0]\n",
    "    return np.squeeze(result_array)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_test1 = ReturnSample(colony_ur,200)\n",
    "sample_test2 = ReturnSample(colony_ur,2000)\n",
    "result = ks2samplepermutation(sample_test1, sample_test2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ks2samplepermutation(data_benchmark, data_test, trials, sample_size=100):\n",
    "    \"\"\"\n",
    "    This function is designed to take a set of the data \"data_benchmark\" and perform a KS statistic permutation test \n",
    "    against a larger sample to determine wether \"data_benchmark\" could have been produced from data with the same\n",
    "    statistical nature as the \"data_test\"\n",
    "    \"\"\"\n",
    "    if (len(data_benchmark)-len(data_test))/len(data_benchmark) < 0.5:\n",
    "        print 'The benchmarking data represents more than half of the total sample size, the test might be meaningless'\n",
    "    result_array = np.ones(trials)\n",
    "    for t in range(0,trials):\n",
    "        result = stats.ks_2samp(data_benchmark, data_test)\n",
    "        result_array[t] = result[0]\n",
    "    return np.squeeze(result_array)   "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
